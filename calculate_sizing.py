#!/usr/bin/env python3
# ============================================================================
# OpenShift ROSA Sizing Calculator
# ============================================================================
#
# This script analyzes metrics collected by collect_metrics.py and provides
# sizing recommendations for Red Hat OpenShift Service on AWS (ROSA) clusters.
#
# The script reads the metrics JSON file and calculates recommended instance
# types, node counts, and other configuration parameters based on usage patterns.
#
# Usage:
#   ./calculate_sizing.py --input metrics.json [options]
#
# Author: OpenShift Sizing Team
# ============================================================================

import json
import argparse
import sys
import os
import math
from datetime import datetime

# ===============================
# Constants for Sizing Calculations
# ===============================
DEFAULT_REDUNDANCY_FACTOR = 1.3
DEFAULT_MAX_PODS_PER_NODE = 250
MIN_WORKER_NODES = 2
CPU_BOUND_THRESHOLD_RATIO = 1.5
MEMORY_BOUND_THRESHOLD_RATIO = 0.67
DEFAULT_STORAGE_IOPS = 3000
HIGH_IOPS_THRESHOLD = 16000
DEFAULT_STORAGE_THROUGHPUT = 125  # MB/s
THROUGHPUT_IOPS_RATIO = 0.8
HOURS_PER_MONTH_AVG = 730  # Approximate
PERCENTILE_KEY = '95th_percentile'
PEAK_KEY = 'peak'
DIVISION_BY_ZERO_AVOIDANCE = 0.0001

def load_instance_types(file_path: str) -> dict:
    """
    Load AWS EC2 instance types from a JSON file.

    Args:
        file_path (str): Path to the instance types JSON file. The file must contain a top-level
            'InstanceTypes' key with a list of instance type objects. Each instance object should include at least:
                - 'InstanceType' (str): The instance type name.
                - 'VCpuInfo' (dict): With 'DefaultVCpus' (int).
                - 'MemoryInfo' (dict): With 'SizeInMiB' (int).
                - Optional: 'BareMetal' (bool), 'Pricing' (dict with region keys).

    Returns:
        dict: Mapping of instance type names to a dict with keys 'vcpu', 'memory_gb', 'bare_metal',
            'hourly_cost', and 'family'.

    Raises:
        FileNotFoundError: If the file does not exist.
        json.JSONDecodeError: If the file is not valid JSON.
        KeyError: If required keys are missing in the JSON structure.
        PermissionError: If the file cannot be read due to permissions.
    """
    try:
        full_path = os.path.join(os.path.dirname(__file__), file_path)
        with open(full_path, 'r') as f:
            data = json.load(f)
        instance_types = {}
        for instance in data['InstanceTypes']:
            instance_type = instance['InstanceType']
            instance_types[instance_type] = {
                'vcpu': instance['VCpuInfo']['DefaultVCpus'],
                'memory_gb': instance['MemoryInfo']['SizeInMiB'] / 1024,
                'bare_metal': instance.get('BareMetal', False),
                'hourly_cost': instance.get('Pricing', {}).get('us-east-1', 0),
                'family': instance['InstanceType'].split('.')[0]
            }
        return instance_types
    except FileNotFoundError as e:
        print(f"Instance types file not found: {e}")
        sys.exit(1)
    except json.JSONDecodeError as e:
        print(f"Error decoding JSON in instance types file: {e}")
        sys.exit(1)
    except KeyError as e:
        print(f"Missing expected key in instance types file: {e}")
        sys.exit(1)
    except PermissionError as e:
        print(f"Permission error reading instance types file: {e}")
        sys.exit(1)

INSTANCE_TYPES = load_instance_types('instance_types.json')

def parse_arguments() -> argparse.Namespace:
    """
    Parse command line arguments for the sizing tool.

    Returns:
        argparse.Namespace: Parsed command line arguments with attributes 'input', 'output', 'format', and 'redundancy'.
    """
    parser = argparse.ArgumentParser(
        description='Calculate ROSA cluster sizing recommendations based on metrics.',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument(
        '--input',
        required=True,
        help='Input metrics JSON file (from collect_metrics.py)'
    )
    parser.add_argument(
        '--output',
        default='rosa_sizing.json',
        help='Output file for sizing recommendations'
    )
    parser.add_argument(
        '--format',
        choices=['json', 'text'],
        default='json',
        help='Output format (json or text)'
    )
    parser.add_argument(
        '--redundancy',
        type=float,
        default=DEFAULT_REDUNDANCY_FACTOR,
        help=f'Redundancy factor for capacity planning (e.g., {DEFAULT_REDUNDANCY_FACTOR} = 30% extra)'
    )
    return parser.parse_args()

def load_metrics(input_file: str) -> dict:
    """
    Load cluster metrics from a JSON file.

    Args:
        input_file (str): Path to the metrics JSON file generated by collect_metrics.py.

    Returns:
        dict: Metrics dictionary as parsed from the JSON file.

    Raises:
        FileNotFoundError: If the file does not exist.
        json.JSONDecodeError: If the file is not valid JSON.
        PermissionError: If the file cannot be read due to permissions.
    """
    try:
        with open(input_file, 'r') as f:
            return json.load(f)
    except FileNotFoundError as e:
        print(f"Metrics file not found: {e}")
        sys.exit(1)
    except json.JSONDecodeError as e:
        print(f"Error decoding JSON in metrics file: {e}")
        sys.exit(1)
    except PermissionError as e:
        print(f"Permission error reading metrics file: {e}")
        sys.exit(1)

def bin_packing_simulation(metrics, instance_type, redundancy, max_pods_per_node=DEFAULT_MAX_PODS_PER_NODE):
    """Simulate bin packing to estimate required nodes using 95th percentile usage and pod density."""
    vcpu_per_node = INSTANCE_TYPES[instance_type]['vcpu']
    memory_per_node = INSTANCE_TYPES[instance_type]['memory_gb']

    # Use 95th percentile if available, fallback to peak
    cpu_95p = metrics['cpu_usage'].get(PERCENTILE_KEY, metrics['cpu_usage'][PEAK_KEY])
    mem_95p = metrics['memory_usage'].get(PERCENTILE_KEY, metrics['memory_usage'][PEAK_KEY])
    pod_95p = metrics['pod_count'].get(PERCENTILE_KEY, metrics['pod_count'][PEAK_KEY])

    # Required resources (95th percentile * redundancy)
    required_cpu = cpu_95p * redundancy
    required_memory = mem_95p * redundancy
    required_pods = pod_95p * redundancy

    nodes_cpu = max(MIN_WORKER_NODES, math.ceil(required_cpu / vcpu_per_node))
    nodes_memory = max(MIN_WORKER_NODES, math.ceil(required_memory / memory_per_node))
    nodes_pods = max(MIN_WORKER_NODES, math.ceil(required_pods / max_pods_per_node))

    recommended_nodes = max(nodes_cpu, nodes_memory, nodes_pods)
    return recommended_nodes, nodes_cpu, nodes_memory, nodes_pods, max_pods_per_node, required_cpu, required_memory, required_pods


def calculate_worker_nodes(metrics, redundancy, profile='balanced', workload_type=None, exclude_bare_metal=True):
    """Calculate recommended worker node configuration using 95th percentile usage, pod density, and instance filtering/sorting."""
    recommendations = []
    for instance_type, specs in INSTANCE_TYPES.items():
        if exclude_bare_metal and specs.get('bare_metal', False):
            continue
        # Workload family bias
        if workload_type == 'CPU-bound' and not instance_type.startswith('c'):
            continue
        if workload_type == 'Memory-bound' and not instance_type.startswith('r'):
            continue
        if workload_type == 'Balanced' and not instance_type.startswith('m'):
            continue
        recommended_nodes, nodes_cpu, nodes_memory, nodes_pods, max_pods_per_node, required_cpu, required_memory, required_pods = bin_packing_simulation(metrics, instance_type, redundancy)
        cpu_util = required_cpu / (recommended_nodes * specs['vcpu'])
        memory_util = required_memory / (recommended_nodes * specs['memory_gb'])
        rationale = (
            f"Node count is the maximum of (using 95th percentile):\n"
            f"- CPU: {nodes_cpu} nodes (CPU 95p: {required_cpu:.2f})\n"
            f"- Memory: {nodes_memory} nodes (Mem 95p: {required_memory:.2f} GB)\n"
            f"- Pod density: {nodes_pods} nodes (Pod 95p: {required_pods:.0f}, max pods per node: {max_pods_per_node})"
        )
        recommendations.append({
            'instance_type': instance_type,
            'node_count': recommended_nodes,
            'specs': specs,
            'utilization': {
                'cpu': cpu_util,
                'memory': memory_util
            },
            'rationale': rationale,
            'estimated_cost': {
                'hourly': specs['hourly_cost'] * recommended_nodes,
                'monthly': specs['hourly_cost'] * recommended_nodes * HOURS_PER_MONTH_AVG,
                'instance_family': specs['family']
            }
        })
    # Sorting by profile
    if profile == 'cost':
        recommendations.sort(key=lambda x: x['estimated_cost']['hourly'])
    elif profile == 'performance':
        recommendations.sort(key=lambda x: (-x['specs']['vcpu'], -x['specs']['memory_gb']))
    else:  # balanced
        recommendations.sort(key=lambda x: (abs(x['utilization']['cpu'] - 1) + abs(x['utilization']['memory'] - 1)))
    return recommendations[:3]

def generate_recommendations(metrics, redundancy):
    """Generate comprehensive sizing recommendations with all three profiles and workload bias."""
    workload_type = detect_workload_type(metrics)
    profiles = {}
    for profile in ['cost', 'balanced', 'performance']:
        recs = calculate_worker_nodes(metrics, redundancy, profile=profile, workload_type=workload_type)
        # If no recommendations found (e.g., workload_type filter is too strict), fall back to no workload_type bias
        if not recs:
            recs = calculate_worker_nodes(metrics, redundancy, profile=profile, workload_type=None)
        profiles[profile] = recs
    storage_recommendations = calculate_storage(metrics, redundancy)
    return {
        'metadata': {
            'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'metrics_collection_window': {
                'start': metrics['metadata'].get('window_start', metrics['metadata'].get('collection_time')),
                'end': metrics['metadata'].get('collection_time'),
                'duration_hours': metrics['metadata'].get('duration_hours', 24)
            },
            'redundancy_factor': redundancy,
            'workload_type': workload_type,
            'profiles': ['cost', 'balanced', 'performance']
        },
        'summary': {
            'current_metrics': {
                'cpu_cores_peak': metrics['cpu_usage']['peak'],
                'memory_gb_peak': metrics['memory_usage']['peak'],
                'pod_count_peak': metrics['pod_count']['peak'],
                'storage_gb_peak': metrics['pvc_storage']['peak']
            }
        },
        'worker_nodes': profiles,
        'storage': storage_recommendations
    }

def calculate_storage(metrics, redundancy):
    """Calculate storage recommendations with IOPS analysis."""
    storage_peak = metrics['pvc_storage']['peak'] * redundancy
    iops_peak = metrics.get('pvc_iops', {}).get('peak', DEFAULT_STORAGE_IOPS) * redundancy
    throughput_peak = metrics.get('pvc_throughput', {}).get('peak', DEFAULT_STORAGE_THROUGHPUT) * redundancy
    
    # Determine storage profile based on IOPS needs
    storage_profile = 'balanced'
    if iops_peak > HIGH_IOPS_THRESHOLD:
        storage_profile = 'high-iops'
    elif iops_peak < DEFAULT_STORAGE_IOPS:
        storage_profile = 'standard'
    
    recommendations = {
        'total_storage_gb': round(storage_peak),
        'performance_requirements': {
            'iops_peak': round(iops_peak),
            'throughput_peak_mbps': round(throughput_peak),
            'storage_profile': storage_profile
        },
        'recommendations': {
            'gp3': {
                'type': 'gp3',
                'description': 'General Purpose SSD',
                'recommended_for': 'Most workloads',
                'min_size_gb': round(storage_peak),
                'min_iops': max(DEFAULT_STORAGE_IOPS, round(iops_peak * THROUGHPUT_IOPS_RATIO)),
                'min_throughput': max(DEFAULT_STORAGE_THROUGHPUT, round(throughput_peak * THROUGHPUT_IOPS_RATIO))
            },
            'io2': {
                'type': 'io2',
                'description': 'Provisioned IOPS SSD',
                'recommended_for': 'I/O-intensive workloads',
                'min_size_gb': round(storage_peak),
                'min_iops': max(100, round(iops_peak * THROUGHPUT_IOPS_RATIO)),
                'min_throughput': max(DEFAULT_STORAGE_THROUGHPUT, round(throughput_peak * THROUGHPUT_IOPS_RATIO))
            }
        }
    }
    
    return recommendations

def detect_workload_type(metrics):
    """Determine if workload is CPU-bound, memory-bound, or balanced."""
    cpu_peak = metrics['cpu_usage']['peak']
    memory_peak = metrics['memory_usage']['peak']
    
    # Calculate ratio of CPU to memory usage
    ratio = cpu_peak / (memory_peak + DIVISION_BY_ZERO_AVOIDANCE)  # Avoid division by zero
    
    if ratio > CPU_BOUND_THRESHOLD_RATIO:
        return 'CPU-bound'
    elif ratio < MEMORY_BOUND_THRESHOLD_RATIO:
        return 'Memory-bound'
    else:
        return 'Balanced'


def format_text_output(recommendations):
    """Format recommendations as human-readable text with all profiles."""
    text = []
    text.append("=" * 80)
    text.append("ROSA Cluster Sizing Recommendations")
    text.append("=" * 80)
    
    text.append("\nGenerated at: " + recommendations['metadata']['generated_at'])
    window = recommendations['metadata']['metrics_collection_window']
    text.append(f"Metrics collection window: {window['start']} to {window['end']} ({window['duration_hours']} hours)")
    text.append(f"Redundancy factor: {recommendations['metadata']['redundancy_factor']}")
    text.append(f"Workload type bias: {recommendations['metadata'].get('workload_type', 'N/A')}")
    text.append(f"Profiles shown: {', '.join(recommendations['metadata'].get('profiles', []))}")
    
    text.append("\nCurrent Usage Peaks:")
    text.append(f"- CPU Cores: {recommendations['summary']['current_metrics']['cpu_cores_peak']:.2f}")
    text.append(f"- Memory (GB): {recommendations['summary']['current_metrics']['memory_gb_peak']:.2f}")
    text.append(f"- Pod Count: {recommendations['summary']['current_metrics']['pod_count_peak']:.0f}")
    text.append(f"- Storage (GB): {recommendations['summary']['current_metrics']['storage_gb_peak']:.2f}")
    
    for profile in ['cost', 'balanced', 'performance']:
        if profile not in recommendations['worker_nodes']:
            continue
        text.append("\n" + "-" * 60)
        text.append(f"{profile.title()} Profile Recommendations:")
        for i, rec in enumerate(recommendations['worker_nodes'][profile], 1):
            text.append(f"\n{i}. {rec['instance_type']} Configuration:")
            text.append(f"   - Number of nodes: {rec['node_count']}")
            text.append(f"   - vCPUs per node: {rec['specs']['vcpu']}")
            text.append(f"   - Memory per node: {rec['specs']['memory_gb']:.1f} GB")
            text.append(f"   - Bare metal: {'Yes' if rec['specs'].get('bare_metal', False) else 'No'}")
            text.append(f"   - CPU utilization: {rec['utilization']['cpu']*100:.1f}%")
            text.append(f"   - Memory utilization: {rec['utilization']['memory']*100:.1f}%")
            text.append(f"   - Rationale: {rec.get('rationale', 'N/A')}")
            text.append(f"   - Estimated Cost:")
            text.append(f"     - Hourly: ${rec['estimated_cost']['hourly']:.2f}")
            text.append(f"     - Monthly: ${rec['estimated_cost']['monthly']:.2f}")
            text.append(f"     - Instance Family: {rec['estimated_cost']['instance_family']}")
    
    text.append("\nStorage Performance Requirements:")
    perf = recommendations['storage']['performance_requirements']
    text.append(f"- Peak IOPS: {perf['iops_peak']}")
    text.append(f"- Peak Throughput: {perf['throughput_peak_mbps']} MB/s")
    text.append(f"- Profile: {perf['storage_profile']}")
    
    text.append("\nStorage Recommendations:")
    text.append(f"Total storage required: {recommendations['storage']['total_storage_gb']} GB")
    for storage_type, details in recommendations['storage']['recommendations'].items():
        text.append(f"\n{storage_type.upper()}:")
        text.append(f"- Type: {details['type']}")
        text.append(f"- Description: {details['description']}")
        text.append(f"- Recommended for: {details['recommended_for']}")
        text.append(f"- Minimum size: {details['min_size_gb']} GB")
        text.append(f"- Minimum IOPS: {details['min_iops']}")
        text.append(f"- Minimum Throughput: {details['min_throughput']} MB/s")
    
    return "\n".join(text)

def main():
    """Main function to run the sizing calculations."""
    args = parse_arguments()
    
    # Load metrics
    metrics = load_metrics(args.input)
    
    # Generate recommendations
    recommendations = generate_recommendations(metrics, args.redundancy)
    
    # Debug: print worker_nodes profiles
    print("\nDEBUG: worker_nodes profiles keys:", recommendations['worker_nodes'].keys())
    for profile, recs in recommendations['worker_nodes'].items():
        print(f"DEBUG: Profile {profile} has {len(recs)} recommendations.")
        if recs:
            print(f"DEBUG: First recommendation for {profile}: {recs[0]}")

    # Save recommendations
    try:
        if args.format == 'json':
            with open(args.output, 'w') as f:
                json.dump(recommendations, f, indent=2)
            print(f"\nRecommendations saved to {args.output}")
            
            # Also create a text summary
            summary_file = args.output.rsplit('.', 1)[0] + '_summary.txt'
            with open(summary_file, 'w') as f:
                f.write(format_text_output(recommendations))
            print(f"Summary saved to {summary_file}")
        else:
            # Save text format
            with open(args.output, 'w') as f:
                f.write(format_text_output(recommendations))
            print(f"\nRecommendations saved to {args.output}")
    except Exception as e:
        print(f"Error saving recommendations: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
